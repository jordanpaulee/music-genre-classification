{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, concatenate\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2  # or use PIL for image handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: C:\\Code\\School\\CSCI416\\music_genre_classification\\music-genre-classification\n"
     ]
    }
   ],
   "source": [
    "working_OS = 'Windows'\n",
    "\n",
    "if working_OS == 'MacOS':\n",
    "    os.chdir(r\"/Users/jordanlee/Code/School/CSCI416/music-genre-classification\")\n",
    "    print(\"Current Working Directory:\", os.getcwd())\n",
    "\n",
    "elif working_OS == 'Windows':\n",
    "    os.chdir(r\"C:\\Code\\School\\CSCI416\\music_genre_classification\\music-genre-classification\")\n",
    "    print(\"Current Working Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/features/aug_features_cleaned.csv')\n",
    "X = df.drop(columns=['label'])\n",
    "y = df['label']\n",
    "label_encoder =LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train_tabular, X_test_tabular, y_train_tabular, y_test_tabular = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spectrogram(audio_path, output_path, sr=22050):\n",
    "    \"\"\"\n",
    "    Generate a spectrogram from an audio file and save it as a PNG.\n",
    "    \n",
    "    Parameters:\n",
    "    - audio_path: Path to the audio file.\n",
    "    - output_path: Path to save the generated spectrogram.\n",
    "    - sr: Sampling rate for loading the audio.\n",
    "    \"\"\"\n",
    "    # Load audio file\n",
    "    y, sr = librosa.load(audio_path, sr=sr)\n",
    "    \n",
    "    # Create a mel-spectrogram\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=8000)\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "    \n",
    "    # Plot and save the spectrogram\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    librosa.display.specshow(S_dB, sr=sr, x_axis='time', y_axis='mel', fmax=8000, cmap='viridis')\n",
    "    plt.axis('off')  # Remove axes for a cleaner PNG\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.savefig(output_path, dpi=100, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_audio_dir = \"data/augmented\"\n",
    "spectrogram_dir = \"data/aug_spectrograms\"\n",
    "\n",
    "# Create spectrogram directory if it doesn't exist\n",
    "os.makedirs(spectrogram_dir, exist_ok=True)\n",
    "\n",
    "# Loop through all audio files in the augmented directory\n",
    "for root, dirs, files in os.walk(augmented_audio_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".wav\"):  # Ensure only audio files are processed\n",
    "            genre = os.path.basename(root)  # Use folder name as genre\n",
    "            genre_dir = os.path.join(spectrogram_dir, genre)\n",
    "            os.makedirs(genre_dir, exist_ok=True)  # Create genre folder if needed\n",
    "            \n",
    "            # File paths\n",
    "            audio_path = os.path.join(root, file)\n",
    "            spectrogram_path = os.path.join(genre_dir, file.replace(\".wav\", \".png\"))\n",
    "            \n",
    "            # Generate spectrogram\n",
    "            generate_spectrogram(audio_path, spectrogram_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram_dir = 'data/aug_spectrograms'  # Path to the spectrograms folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spectrograms_and_labels(spectrogram_dir):\n",
    "    spectrograms = []  # List to store spectrogram data\n",
    "    labels = []        # List to store genre labels\n",
    "    \n",
    "    # Loop through all subdirectories (each representing a genre)\n",
    "    for genre in os.listdir(spectrogram_dir):\n",
    "        genre_folder = os.path.join(spectrogram_dir, genre)\n",
    "        \n",
    "        # Skip files, process only directories\n",
    "        if os.path.isdir(genre_folder):\n",
    "            for img_file in os.listdir(genre_folder):\n",
    "                img_path = os.path.join(genre_folder, img_file)\n",
    "                \n",
    "                # Read the image using PIL (you can resize or preprocess here if needed)\n",
    "                img = Image.open(img_path).convert('L')  # Convert to grayscale ('L')\n",
    "                img = img.resize((128, 128))  # Resize to 128x128 (adjust as needed)\n",
    "                \n",
    "                # Convert image to numpy array\n",
    "                img_array = np.array(img)\n",
    "                \n",
    "                # Append the image and its genre label\n",
    "                spectrograms.append(img_array)\n",
    "                labels.append(genre)  # The genre is the label for classification\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    X_spectrograms = np.array(spectrograms)\n",
    "    y_labels = np.array(labels)\n",
    "    \n",
    "    return X_spectrograms, y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spectrograms and labels\n",
    "X_spectrograms, y_labels = load_spectrograms_and_labels(spectrogram_dir)\n",
    "\n",
    "# Normalize pixel values (between 0 and 1)\n",
    "X_spectrograms = X_spectrograms.astype('float32') / 255.0\n",
    "\n",
    "# Reshape to add channel dimension (since images are grayscale, the channel is 1)\n",
    "X_spectrograms = X_spectrograms.reshape(-1, 128, 128, 1)\n",
    "\n",
    "# Encode labels (genres) as numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "y_labels_encoded = label_encoder.fit_transform(y_labels)\n",
    "\n",
    "# Optional: one-hot encode the labels if needed (for multi-class classification)\n",
    "y_labels_one_hot = np.eye(len(label_encoder.classes_))[y_labels_encoded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (80% train, 20% test)\n",
    "X_train_spectrogram, X_test_spectrogram, y_train, y_test = train_test_split(\n",
    "    X_spectrograms, y_labels_one_hot, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,776</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57600</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57632</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,377,024</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m,  │        \u001b[38;5;34m320\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m,    │     \u001b[38;5;34m18,496\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m3,776\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57600\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_3[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57632\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │  \u001b[38;5;34m7,377,024\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m650\u001b[0m │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,410,602</span> (28.27 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,410,602\u001b[0m (28.27 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,410,602</span> (28.27 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,410,602\u001b[0m (28.27 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the input for tabular data\n",
    "tabular_input = layers.Input(shape=(X_train_tabular.shape[1],))  # Adjust shape based on your tabular data\n",
    "\n",
    "# Define the input for spectrogram images\n",
    "spectrogram_input = layers.Input(shape=(128, 128, 1))  # Adjust shape based on your spectrogram size\n",
    "\n",
    "# Tabular data processing: Dense layers\n",
    "tabular_x = layers.Dense(64, activation='relu')(tabular_input)\n",
    "tabular_x = layers.Dense(32, activation='relu')(tabular_x)\n",
    "\n",
    "# Spectrogram data processing: Convolutional layers\n",
    "spectrogram_x = layers.Conv2D(32, (3, 3), activation='relu')(spectrogram_input)\n",
    "spectrogram_x = layers.MaxPooling2D((2, 2))(spectrogram_x)\n",
    "spectrogram_x = layers.Conv2D(64, (3, 3), activation='relu')(spectrogram_x)\n",
    "spectrogram_x = layers.MaxPooling2D((2, 2))(spectrogram_x)\n",
    "spectrogram_x = layers.Flatten()(spectrogram_x)\n",
    "\n",
    "# Concatenate the two branches (tabular and spectrogram)\n",
    "combined = layers.concatenate([tabular_x, spectrogram_x])\n",
    "\n",
    "# Dense layers after concatenation\n",
    "x = layers.Dense(128, activation='relu')(combined)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "# Output layer (for classification)\n",
    "output = layers.Dense(y_train.shape[1], activation='softmax')(x)  # Softmax for multi-class classification\n",
    "\n",
    "# Define the model\n",
    "model = models.Model(inputs=[tabular_input, spectrogram_input], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model summary to visualize the architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ImageDataGenerator for augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,       # Random rotations\n",
    "    width_shift_range=0.2,   # Random width shifts\n",
    "    height_shift_range=0.2,  # Random height shifts\n",
    "    shear_range=0.2,         # Random shearing\n",
    "    zoom_range=0.2,          # Random zoom\n",
    "    horizontal_flip=True,    # Random horizontal flip\n",
    "    fill_mode='nearest'      # Fill missing pixels after transformations\n",
    ")\n",
    "\n",
    "# Fit the generator on your training data\n",
    "datagen.fit(X_train_spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m  75/2397\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:30\u001b[0m 91ms/step - accuracy: 0.1785 - loss: 2.2540"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jplee\\anaconda3\\envs\\genre_classification\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2397/2397\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.2606 - loss: 2.0725 - val_accuracy: 0.4150 - val_loss: 1.6378\n",
      "Epoch 2/10\n",
      "\u001b[1m2397/2397\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.5148 - loss: 1.3277 - val_accuracy: 0.5433 - val_loss: 1.2533\n",
      "Epoch 3/10\n",
      "\u001b[1m2397/2397\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.6285 - loss: 1.0722 - val_accuracy: 0.6200 - val_loss: 1.0889\n",
      "Epoch 4/10\n",
      "\u001b[1m2397/2397\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.6834 - loss: 0.9115 - val_accuracy: 0.6050 - val_loss: 1.0655\n",
      "Epoch 5/10\n",
      "\u001b[1m2397/2397\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7457 - loss: 0.7282 - val_accuracy: 0.6933 - val_loss: 0.9087\n",
      "Epoch 6/10\n",
      "\u001b[1m2397/2397\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8254 - loss: 0.5243 - val_accuracy: 0.7267 - val_loss: 0.8400\n",
      "Epoch 7/10\n",
      "\u001b[1m2397/2397\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8822 - loss: 0.3698 - val_accuracy: 0.7517 - val_loss: 0.8191\n",
      "Epoch 8/10\n",
      "\u001b[1m2397/2397\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9171 - loss: 0.2653 - val_accuracy: 0.7117 - val_loss: 0.9439\n",
      "Epoch 9/10\n",
      "\u001b[1m2397/2397\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9671 - loss: 0.1425 - val_accuracy: 0.7650 - val_loss: 0.7745\n",
      "Epoch 10/10\n",
      "\u001b[1m2397/2397\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9876 - loss: 0.0770 - val_accuracy: 0.7483 - val_loss: 0.8567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x25a83246380>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    [X_train_tabular, X_train_spectrogram], y_train,\n",
    "    epochs=10, batch_size=32, validation_data=([X_test_tabular, X_test_spectrogram], y_test),\n",
    "    steps_per_epoch=len(X_train_spectrogram)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7515 - loss: 0.9670\n",
      "Test loss: 0.8567209839820862\n",
      "Test accuracy: 0.7483333349227905\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate([X_test_tabular, X_test_spectrogram], y_test)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Test loss: {test_loss}\")\n",
    "print(f\"Test accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
      "Predicted classes: [4 4 0 9 0]\n",
      "True classes: [[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred = model.predict([X_test_tabular, X_test_spectrogram])\n",
    "\n",
    "# Convert predictions to class labels (if using softmax, for classification)\n",
    "y_pred_classes = y_pred.argmax(axis=1)\n",
    "\n",
    "# Print predictions for the first few test samples\n",
    "print(f\"Predicted classes: {y_pred_classes[:5]}\")\n",
    "print(f\"True classes: {y_test[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: [4 4 0 9 0]\n",
      "True classes: [4 3 0 9 0]\n"
     ]
    }
   ],
   "source": [
    "# Convert y_test (one-hot encoded) to integer labels\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Now compare the predicted classes with the true class labels\n",
    "print(f\"Predicted classes: {y_pred_classes[:5]}\")\n",
    "print(f\"True classes: {y_test_classes[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[46  0 15  2  0  4  0  1  1  4]\n",
      " [ 0 66  0  0  0  2  0  1  0  0]\n",
      " [ 4  0 50  0  0  1  0  0  2  1]\n",
      " [ 0  0  6 39  4  2  0  4  3  1]\n",
      " [ 0  0  1  2 44  0  1  0  2  3]\n",
      " [ 5  3  3  1  0 37  0  0  0  2]\n",
      " [ 2  0  0  0  3  0 46  0  0  5]\n",
      " [ 1  1  5  6  2  0  0 40  1  1]\n",
      " [ 0  0  4  3  3  0  0  4 44  0]\n",
      " [ 2  0 12  8  0  0  2  2  3 37]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.63      0.69        73\n",
      "           1       0.94      0.96      0.95        69\n",
      "           2       0.52      0.86      0.65        58\n",
      "           3       0.64      0.66      0.65        59\n",
      "           4       0.79      0.83      0.81        53\n",
      "           5       0.80      0.73      0.76        51\n",
      "           6       0.94      0.82      0.88        56\n",
      "           7       0.77      0.70      0.73        57\n",
      "           8       0.79      0.76      0.77        58\n",
      "           9       0.69      0.56      0.62        66\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.76      0.75      0.75       600\n",
      "weighted avg       0.76      0.75      0.75       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Classification Report (precision, recall, f1-score)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_classes, y_pred_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genre_classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
